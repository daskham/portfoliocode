__author__ = 'derek'
import tweepy
import pandas as pd
from matplotlib import pyplot as plt
from termcolor import colored
import numpy
import csv
import sys
import pprint
import time

pd.options.display.max_columns = 100
pd.options.display.max_rows = 150
pd.options.display.width = 120


consumer_key = ""
consumer_secret = ""

auth = tweepy.OAuthHandler(consumer_key=consumer_key, consumer_secret=consumer_secret)


api = tweepy.API(auth)

hash_tag_search = raw_input("What hashtag do you wish to create a wordcloud? ").encode(encoding="utf-8")

results = api.search(q=hash_tag_search)

len(results)

def print_tweet(tweet):
    print "@%s = %s (%s)" % (tweet.user.screen_name, tweet.user.name, tweet.created_at)
    print tweet.text

tweet = results[1]
print_tweet(tweet)

tweet = results[2]

# inspecting a Status Object. This is the construction of a tweet
for param in dir(tweet):
    if not param.startswith("_"):
        print "%s : %s" % (param, eval("tweet." + param))
print colored("Inspected Status Object Successful", "green")

# inspecting a User object
user = tweet.author

for param in dir(user):
    if not param.startswith("_"):
        print "%s : %s" % (param, eval("user." + param))
print colored("Inspected User Object Successful", "green")
# Cursor for Pagination
results = []
for tweet in tweepy.Cursor(api.search, q=hash_tag_search).items(100):
    results.append(tweet)

print colored(len(results), "yellow")

# store the results in a data frame
def process_results(results):
    id_list = [tweet.id for tweet in results]
    data_set = pd.DataFrame(id_list, columns=["id"])

    # processing tweet data
    data_set["text"] = [tweet.text for tweet in results]
    data_set["created_at"] = [tweet.created_at for tweet in results]
    data_set["retweet_count"] = [tweet.retweet_count for tweet in results]
    data_set["favorite_count"] = [tweet.favorite_count for tweet in results]
    data_set["source"] = [tweet.source for tweet in results]

    # processing user data
    data_set["user_id"] = [tweet.author.id for tweet in results]
    data_set["user_screen_name"] = [tweet.author.screen_name for tweet in results]
    data_set["user_name"] = [tweet.author.name for tweet in results]
    data_set["user_created_at"] = [tweet.author.created_at for tweet in results]
    data_set["user_description"] = [tweet.author.description for tweet in results]
    data_set["user_followers_count"] = [tweet.author.followers_count for tweet in results]
    data_set["user_friends_count"] = [tweet.author.friends_count for tweet in results]
    data_set["user_location"] = [tweet.author.location for tweet in results]

    return data_set

data_set = process_results(results)

print data_set

sources = data_set["source"].value_counts()[:5][::-1]

def plt_func(sources):
    plt.barh(xrange(len(sources)), sources.values)
    plt.yticks(numpy.arange(len(sources)) + 0.4, sources.index)
    plt.show()

# plt_func(sources)

# data_set.to_json("myfilename.json")

results_json = []
def get_tweets_separate(results):
    id_list = [tweet.id for tweet in results]
    results_csv = pd.DataFrame(id_list, columns=["id"])

    results_csv["text"] = [tweet.text for tweet in results]
    results_csv["created_at"] = [tweet.created_at for tweet in results]
    results_csv["retweet_count"] = [tweet.retweet_count for tweet in results]
    results_csv["favorite_count"] = [tweet.favorite_count for tweet in results]
    results_csv["source"] = [tweet.source for tweet in results]

    # processing user data
    results_csv["user_id"] = [tweet.author.id for tweet in results]
    results_csv["user_screen_name"] = [tweet.author.screen_name for tweet in results]
    results_csv["user_name"] = [tweet.author.name for tweet in results]
    results_csv["user_created_at"] = [tweet.author.created_at for tweet in results]
    results_csv["user_description"] = [tweet.author.description for tweet in results]
    results_csv["user_followers_count"] = [tweet.author.followers_count for tweet in results]
    results_csv["user_friends_count"] = [tweet.author.friends_count for tweet in results]
    results_csv["user_location"] = [tweet.author.location for tweet in results]

    return results_csv

results_csv = get_tweets_separate(results)

pprint.pprint(data_set)

# data_set.to_csv("data_set_index.csv", header=True, sep=",", encoding="utf-8")

# data_set.to_json(hash_tag_search + ".json", orient='index')
print("Writing CSV, please Wait")
results_csv.to_csv(hash_tag_search + "_data_" + time.strftime("%x").replace("/", "-") + ".csv", header=True, encoding="utf-8")
print("CSV Finished")
